# Prometheus Ultimate Deep Dive: Фундаментальное руководство по наблюдаемости

**Автор:** Oleborn
**Дата:** 14 февраля 2026 г.  
**Проект:** [OrderHub](https://github.com/Oleborn/OrderHub)

---

## 1. Введение: Prometheus как краеугольный камень наблюдаемости

В эпоху распределенных систем и микросервисов, понимание состояния приложения в реальном времени становится критически важным. Prometheus, изначально разработанный в SoundCloud, а затем ставший частью Cloud Native Computing Foundation (CNCF), зарекомендовал себя как де-факто стандарт для мониторинга и алертинга. Это не просто инструмент, а целая философия, позволяющая инженерам задавать сложные вопросы о поведении системы и получать на них ответы.

В этом документе мы совершим глубокое погружение в архитектуру, внутреннее устройство и продвинутые возможности Prometheus, выходя за рамки базового использования и затрагивая аспекты, необходимые для построения production-ready систем мониторинга.

---

## 2. Архитектура Prometheus: От Scrape до Storage

Prometheus — это не монолит, а набор взаимосвязанных компонентов, работающих в унисон. Его ключевая особенность — **Pull-модель** сбора метрик, которая кардинально отличается от традиционных Push-систем.

### 2.1. Pull-модель: Философия сбора метрик

В отличие от Push-модели, где приложение активно отправляет метрики на сервер мониторинга, Prometheus сам инициирует сбор данных, периодически опрашивая (scraping) сконфигурированные цели (targets). Эта модель имеет ряд фундаментальных преимуществ:

*   **Контроль со стороны сервера:** Prometheus полностью контролирует частоту и объем сбора данных, предотвращая перегрузку сервера мониторинга при всплесках активности в приложениях.
*   **Автоматический Health Check:** Если Prometheus не может получить метрики от цели, это немедленно сигнализирует о проблемах с доступностью приложения или сети. В Prometheus есть встроенная метрика `up`, которая показывает статус каждой цели.
*   **Упрощение конфигурации целей:** Приложение не должно знать, где находится сервер мониторинга. Ему достаточно выставить HTTP-эндпоинт `/metrics` в определенном формате.
*   **Динамическое обнаружение:** В облачных средах, где IP-адреса и количество экземпляров приложений постоянно меняются, Pull-модель отлично сочетается с Service Discovery.

### 2.2. Основные компоненты экосистемы Prometheus

1.  **Prometheus Server:**
    *   **Retrieval (Scraper):** Модуль, отвечающий за периодический опрос целей и сбор метрик.
    *   **Time Series Database (TSDB):** Локальная база данных, оптимизированная для хранения временных рядов.
    *   **HTTP Server:** Предоставляет API для выполнения запросов PromQL, а также веб-интерфейс для отладки и визуализации.
2.  **Service Discovery:** Интеграции с различными платформами (Kubernetes, AWS EC2, Consul, DNS, Static Config) для автоматического обнаружения целей мониторинга. Это позволяет Prometheus динамически адаптироваться к изменениям в инфраструктуре.
3.  **Exporters:** Промежуточные агенты, которые собирают метрики из систем, не поддерживающих формат Prometheus (например, базы данных, брокеры сообщений, операционные системы) и конвертируют их в формат Prometheus. Примеры: Node Exporter (для ОС), cAdvisor (для контейнеров), JMX Exporter (для JVM-приложений).
4.  **Pushgateway:** Специальный компонент для сбора метрик от короткоживущих задач (batch jobs), которые не могут быть опрошены Prometheus напрямую. Метрики отправляются в Pushgateway, а Prometheus уже опрашивает его.
5.  **Alertmanager:** Отдельный сервис, который обрабатывает алерты, сгенерированные Prometheus. Он отвечает за дедупликацию, группировку, подавление (silencing) и маршрутизацию уведомлений в различные каналы (Slack, PagerDuty, Email).
6.  **Grafana:** Хотя и не является частью Prometheus, Grafana — это де-факто стандарт для визуализации метрик, собранных Prometheus. Она предоставляет мощные инструменты для построения интерактивных дашбордов.

---

## 3. TSDB: Хранение и оптимизация временных рядов

Сердцем Prometheus является его собственная Time Series Database (TSDB), разработанная с нуля для эффективного хранения и запросов временных рядов. Она оптимизирована для **высокой скорости записи** и **быстрого чтения недавних данных**.

### 3.1. Структура данных на диске: Head Block и Persistent Blocks

TSDB управляет данными, разделяя их на две основные части:

*   **Head Block (In-Memory + WAL):** Это активный блок, который хранит самые свежие данные (обычно за последние 2 часа) в оперативной памяти. Все новые образцы (samples) сначала записываются сюда. Для обеспечения отказоустойчивости, все записи в Head Block также дублируются в **Write-Ahead Log (WAL)** на диске. В случае падения Prometheus, WAL используется для восстановления состояния Head Block.
*   **Persistent Blocks (On-Disk):** Когда данные в Head Block достигают определенного возраста (по умолчанию 2 часа), они сбрасываются на диск в виде неизменяемого Persistent Block. Каждый такой блок является полностью независимой единицей хранения со своим собственным индексом. Эти блоки хранятся в отдельных директориях в файловой системе.

**Пример структуры директории `/data`:**

```
/data
├── wal/                  # Write-Ahead Log для Head Block
├── 01H.../               # Директория первого Persistent Block (например, 2 часа данных)
│   ├── meta.json         # Метаданные блока (диапазон времени, статистика)
│   ├── index             # Инвертированный индекс для этого блока
│   ├── chunks/           # Директория с файлами чанков (сжатые данные метрик)
│   └── tombstones        # Флаги удаленных временных рядов (физическое удаление при компакции)
├── 01I.../               # Директория второго Persistent Block
└── lock                  # Файл блокировки для эксклюзивного доступа
```

### 3.2. Компрессия данных: Алгоритм Gorilla

Для минимизации объема хранимых данных Prometheus использует адаптацию алгоритма компрессии Gorilla, разработанного Facebook. Этот алгоритм позволяет достичь впечатляющих результатов — в среднем **1.37 байта на один образец**.

*   **Сжатие временных меток (Timestamps):** Вместо хранения абсолютных значений, сохраняются дельты между последовательными временными метками. Если дельты повторяются, используется кодирование "Delta-of-Delta".
*   **Сжатие значений (Values):** Для значений с плавающей точкой (Float64) используется XOR-кодирование. Если текущее значение мало отличается от предыдущего, XOR-операция даст много нулей в начале, что позволяет эффективно сжимать данные, записывая только изменившиеся биты.

### 3.3. Инвертированный индекс: Быстрый поиск по тегам

Для быстрого поиска временных рядов по их меткам (labels) Prometheus использует **инвертированный индекс**, аналогичный тому, что применяется в поисковых системах. Индекс сопоставляет пары `ключ=значение` метки с набором идентификаторов временных рядов (Series IDs).

*   Когда вы выполняете запрос `http_requests_total{job=
```promql
http_requests_total{job="my_app", instance="server1"}
```
Prometheus сначала находит все Series IDs, соответствующие `job="my_app"`, затем фильтрует их по `instance="server1"`, и только после этого извлекает данные для этих Series IDs.

### 3.4. mmap (Memory Mapped Files): Эффективное использование памяти

При чтении старых блоков данных Prometheus не управляет кешем самостоятельно. Вместо этого он использует **Memory Mapped Files (mmap)**, делегируя управление кешем операционной системе. Это позволяет:

*   **Избежать давления на GC:** Данные, отображенные в память через `mmap`, находятся вне кучи Go-приложения и не подвергаются сборке мусора, что снижает накладные расходы.
*   **Использовать всю доступную память:** ОС может использовать всю свободную память для кеширования блоков, что значительно ускоряет доступ к часто запрашиваемым данным.
*   **Эффективность:** ОС лучше знает, какие страницы памяти выгружать, а какие оставлять в кеше, основываясь на глобальной картине использования ресурсов.

Однако, при использовании `mmap` в контейнерных средах важно учитывать лимиты памяти (cgroup), чтобы избежать OOM Killer и свопинга.

---

## 4. PromQL: Язык запросов для анализа временных рядов

**PromQL (Prometheus Query Language)** — это функциональный язык запросов, который позволяет выбирать и агрегировать данные временных рядов в реальном времени. Он разработан специально для работы с метриками Prometheus и является одним из самых мощных инструментов в его арсенале.

### 4.1. Типы данных PromQL

PromQL оперирует четырьмя основными типами данных:

*   **Instant vector (мгновенный вектор):** Набор временных рядов, содержащих по одному образцу для каждой серии, все с одной и той же временной меткой. Например, `http_requests_total`.
*   **Range vector (вектор диапазона):** Набор временных рядов, содержащих диапазон образцов для каждой серии за определенный интервал времени. Например, `http_requests_total[5m]`.
*   **Scalar (скаляр):** Простое числовое значение с плавающей точкой. Например, `10`.
*   **String (строка):** Строковое значение. В PromQL используется редко, в основном для внутренних целей.

### 4.2. Селекторы и фильтрация

Выборка метрик начинается с селекторов. Вы можете выбрать метрики по их имени и/или по набору меток.

*   **Выборка по имени метрики:** `http_requests_total` выберет все временные ряды с этим именем.
*   **Выборка по меткам:** `http_requests_total{job="my_app", instance="server1"}` выберет метрики с указанными метками.
*   **Операторы сопоставления меток:**
    *   `=` (равно): Точное совпадение.
    *   `!=` (не равно): Несовпадение.
    *   `=~` (регулярное выражение): Совпадение с регулярным выражением. Например, `{status=~"5.."}` для всех 5xx ошибок.
    *   `!~` (не регулярное выражение): Несовпадение с регулярным выражением.

### 4.3. Функции и операторы PromQL

PromQL предоставляет богатый набор функций для агрегации, трансформации и анализа данных.

*   **Агрегирующие операторы:** `sum()`, `avg()`, `min()`, `max()`, `count()`, `stddev()`, `stdvar()`, `topk()`, `bottomk()`, `quantile()`.
    *   Могут использоваться с `by` или `without` для группировки результатов по меткам. Например, `sum by (job) (http_requests_total)`.
*   **Функции для счетчиков (Counters):**
    *   `rate(v range-vector)`: Вычисляет среднюю скорость роста временного ряда за указанный диапазон. Идеально для QPS.
    *   `irate(v range-vector)`: Вычисляет мгновенную скорость роста, используя только последние два образца. Более чувствителен к резким изменениям.
    *   `increase(v range-vector)`: Вычисляет увеличение счетчика за указанный диапазон.
*   **Функции для гистограмм (Histograms):**
    *   `histogram_quantile(φ scalar, b instant-vector)`: Вычисляет перцентиль `φ` (0 <= φ <= 1) для гистограммы. Используется для расчета p95, p99 latency.
*   **Математические операторы:** `+`, `-`, `*`, `/`, `%`, `^`.
*   **Логические операторы:** `and`, `or`, `unless`.
*   **Операторы сравнения:** `==`, `!=`, `>`, `<`, `>=`, `<=`.

### 4.4. Примеры PromQL для OrderHub (расширенные)

| Задача | Запрос PromQL | Описание | Примечания |
| :--- | :--- | :--- | :--- |
| **QPS (Общий)** | `sum(rate(http_server_requests_seconds_count{application="orderhub"}[1m]))` | Общее количество запросов в секунду ко всем эндпоинтам приложения за последнюю минуту. | Используем `sum()` без `by` для получения общего значения. |
| **QPS по эндпоинтам** | `sum by (uri) (rate(http_server_requests_seconds_count{application="orderhub"}[1m]))` | Количество запросов в секунду, сгруппированное по URI. | Позволяет увидеть нагрузку на каждый эндпоинт. |
| **Latency p95 (Общая)** | `histogram_quantile(0.95, sum by (le) (rate(http_server_requests_seconds_bucket{application="orderhub"}[5m])))` | 95-й перцентиль времени ответа для всех запросов за последние 5 минут. | Важно для понимания пользовательского опыта. |
| **Latency p99 по эндпоинтам** | `histogram_quantile(0.99, sum by (le, uri) (rate(http_server_requests_seconds_bucket{application="orderhub"}[5m])))` | 99-й перцентиль времени ответа, сгруппированный по URI. | Помогает выявить "медленные" эндпоинты. |
| **Процент ошибок (5xx)** | `sum(rate(http_server_requests_seconds_count{application="orderhub", status=~"5.."}[1m])) / sum(rate(http_server_requests_seconds_count{application="orderhub"}[1m])) * 100` | Процент запросов, завершившихся с 5xx ошибками, за последнюю минуту. | Индикатор стабильности сервиса. |
| **Количество созданных заказов (успешно)** | `sum(orders_created_total_total{application="orderhub", status="success"})` | Общее количество успешно созданных заказов с момента запуска приложения. | Бизнес-метрика. |
| **Скорость создания заказов (успешно)** | `rate(orders_created_total_total{application="orderhub", status="success"}[5m])` | Скорость создания заказов в секунду за последние 5 минут. | Бизнес-метрика. |
| **Среднее время создания заказа** | `rate(orders_creation_duration_seconds_sum{application="orderhub"}[5m]) / rate(orders_creation_duration_seconds_count{application="orderhub"}[5m])` | Среднее время выполнения операции создания заказа за последние 5 минут. | Для таймеров Micrometer. |

---

## 5. Service Discovery: Динамическое обнаружение целей

В динамических средах, таких как Kubernetes, виртуальные машины или облачные инстансы, IP-адреса и количество экземпляров приложений постоянно меняются. Prometheus не может быть сконфигурирован статически для таких сценариев. Здесь на помощь приходит **Service Discovery (SD)**.

Prometheus поддерживает множество механизмов SD, позволяющих ему автоматически обнаруживать, добавлять и удалять цели для сбора метрик.

### 5.1. Популярные механизмы Service Discovery

*   **Kubernetes SD:** Prometheus может напрямую взаимодействовать с Kubernetes API для обнаружения подов, сервисов, ингрессов и эндпоинтов. Это наиболее распространенный способ в K8s-кластерах.
*   **Consul SD:** Интеграция с HashiCorp Consul для обнаружения сервисов, зарегистрированных в Consul.
*   **EC2 SD:** Обнаружение инстансов Amazon EC2.
*   **DNS SD:** Обнаружение целей через DNS SRV-записи.
*   **Static Config:** Самый простой способ, когда цели задаются вручную в `prometheus.yml`. Подходит для небольших, статичных сред.

### 5.2. Конфигурация Service Discovery (пример Kubernetes)

```yaml
scrape_configs:
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      # Только поды с аннотацией prometheus.io/scrape=true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      # Используем порт из аннотации prometheus.io/port
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: (\d+)
        target_label: __address__
        replacement: ${1}
      # Добавляем метки из Kubernetes
      - source_labels: [__meta_kubernetes_pod_label_app]
        action: replace
        target_label: app
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: namespace
```

---

## 6. Relabeling: Мощная трансформация меток

**Relabeling** — это один из самых мощных, но и самых сложных механизмов в Prometheus. Он позволяет динамически изменять, добавлять, удалять или фильтровать метки (labels) временных рядов на этапе сбора метрик. Это происходит до того, как метрики будут сохранены в TSDB, что критически важно для управления кардинальностью и чистотой данных.

Relabeling-правила применяются к набору меток, которые Prometheus получает от Service Discovery или Exporter. Эти метки включают как стандартные (например, `__address__`, `__metrics_path__`), так и мета-метки, предоставляемые Service Discovery (например, `__meta_kubernetes_pod_name`).

### 6.1. Основные параметры Relabeling

Каждое правило `relabel_config` состоит из следующих полей:

*   `source_labels`: Список меток, значения которых будут конкатенированы для использования в `regex`. По умолчанию используется `__address__`.
*   `separator`: Разделитель, используемый при конкатенации `source_labels`. По умолчанию `;`.
*   `regex`: Регулярное выражение, применяемое к конкатенированным `source_labels`. Захватывающие группы (`()`) могут быть использованы в `replacement`.
*   `target_label`: Имя метки, в которую будет записан результат `replacement`.
*   `replacement`: Строка замены. Может содержать ссылки на захватывающие группы из `regex` (например, `$1`, `$2`). По умолчанию `$1`.
*   `action`: Действие, которое будет выполнено. Наиболее распространенные:
    *   `replace`: Заменяет `target_label` значением из `replacement` (по умолчанию).
    *   `keep`: Сохраняет цель, если `regex` совпадает. Если не совпадает, цель отбрасывается.
    *   `drop`: Отбрасывает цель, если `regex` совпадает. Если не совпадает, цель сохраняется.
    *   `labelmap`: Копирует все метки, чьи имена совпадают с `regex`, в новые метки, используя `replacement` как шаблон для имени новой метки.
    *   `labeldrop`: Удаляет все метки, чьи имена совпадают с `regex`.
    *   `labelkeep`: Удаляет все метки, чьи имена *не* совпадают с `regex`.

### 6.2. Примеры Relabeling для OrderHub

Предположим, мы хотим:

1.  Отфильтровать все метрики, кроме тех, что относятся к нашему приложению `orderhub`.
2.  Добавить кастомную метку `environment: production`.
3.  Удалить внутренние метки Prometheus, которые не нужны для анализа.

```yaml
scrape_configs:
  - job_name: 'orderhub-app'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['orderhub-app:8080']
    relabel_configs:
      # 1. Отфильтровать по job_name (если у нас несколько приложений на одном Prometheus)
      - source_labels: [__address__]
        regex: 'orderhub-app:8080'
        action: keep

      # 2. Добавить метку environment=production
      - target_label: environment
        replacement: production
        action: replace

      # 3. Удалить все метки, начинающиеся с '__'
      - regex: '__.*'
        action: labeldrop

      # 4. Переименовать метку instance в host
      - source_labels: [instance]
        target_label: host
        action: replace
```

Relabeling — это мощный инструмент для управления жизненным циклом меток, позволяющий создавать чистые и осмысленные наборы данных для мониторинга.

---

## 7. Recording Rules и Alerting Rules: Оптимизация и оповещения

Prometheus позволяет не только собирать и запрашивать метрики, но и создавать новые метрики на основе существующих (Recording Rules) и генерировать оповещения (Alerting Rules).

### 7.1. Recording Rules: Предварительная агрегация и оптимизация

Recording Rules позволяют предварительно вычислять часто используемые или ресурсоемкие PromQL-запросы и сохранять их результаты как новые временные ряды. Это значительно ускоряет построение дашбордов и выполнение запросов, особенно для сложных агрегаций.

**Пример Recording Rule для OrderHub:**

```yaml
# prometheus.rules.yml

groups:
  - name: orderhub-recording-rules
    rules:
      - record: job:http_requests_total:rate5m
        expr: sum by (job, uri) (rate(http_server_requests_seconds_count[5m]))
      - record: job:http_request_duration_seconds:p95_5m
        expr: histogram_quantile(0.95, sum by (job, uri, le) (rate(http_server_requests_seconds_bucket[5m])))
```

Теперь вместо выполнения сложного запроса для QPS, Grafana может просто запросить `job:http_requests_total:rate5m`, что будет намного быстрее.

### 7.2. Alerting Rules: Обнаружение проблем

Alerting Rules определяют условия, при которых Prometheus должен сгенерировать алерт. Эти алерты затем отправляются в Alertmanager для дальнейшей обработки.

**Пример Alerting Rule для OrderHub:**

```yaml
# prometheus.rules.yml

groups:
  - name: orderhub-alerts
    rules:
      - alert: HighErrorRate
        expr: sum(rate(http_server_requests_seconds_count{application="orderhub", status=~"5.."}[5m])) / sum(rate(http_server_requests_seconds_count{application="orderhub"}[5m])) * 100 > 5
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Высокий процент 5xx ошибок в OrderHub"
          description: "Процент 5xx ошибок превысил 5% за последние 5 минут. Текущее значение: {{ $value }}%"

      - alert: OrderCreationLatencyHigh
        expr: histogram_quantile(0.99, sum by (le) (rate(orders_creation_duration_seconds_bucket{application="orderhub"}[5m]))) > 1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Высокая задержка создания заказов в OrderHub"
          description: "99-й перцентиль времени создания заказов превысил 1 секунду за последние 2 минуты. Текущее значение: {{ $value }}s"
```

*   `expr`: PromQL-запрос, который возвращает 1, если условие алерта истинно, и 0 в противном случае.
*   `for`: Как долго условие должно быть истинным, прежде чем алерт будет активирован.
*   `labels`: Дополнительные метки для алерта (например, `severity`).
*   `annotations`: Дополнительная информация для Alertmanager (summary, description).

---

## 8. Масштабирование Prometheus: Федерация и Удаленное хранение

Prometheus, как и любая система, имеет свои ограничения по масштабированию. Для решения этих проблем существуют различные подходы.

### 8.1. Федерация (Federation)

Федерация позволяет одному Prometheus-серверу собирать метрики с других Prometheus-серверов. Это полезно для:

*   **Иерархического мониторинга:** Например, один глобальный Prometheus собирает агрегированные метрики со множества региональных Prometheus-серверов.
*   **Разделения ответственности:** Каждый отдел или команда может иметь свой Prometheus, а центральный Prometheus собирает только ключевые метрики.

### 8.2. Удаленное хранение (Remote Write/Read)

Prometheus хранит данные локально, что ограничивает его масштабируемость и долгосрочное хранение. Для решения этой проблемы Prometheus поддерживает интеграцию с внешними системами хранения через API Remote Write и Remote Read.

*   **Remote Write:** Prometheus может отправлять все собранные метрики в удаленную систему хранения (например, Thanos, Cortex, VictoriaMetrics, Mimir). Это позволяет использовать Prometheus как сборщик метрик, а для долгосрочного хранения и глобальных запросов использовать более масштабируемые решения.
*   **Remote Read:** Позволяет Prometheus запрашивать исторические данные из удаленной системы хранения.

### 8.3. Thanos, Cortex, VictoriaMetrics, Mimir

Эти проекты являются популярными решениями для масштабирования Prometheus, предоставляя такие возможности, как:

*   **Долгосрочное хранение:** Хранение метрик за многие годы.
*   **Глобальный вид:** Объединение данных со множества Prometheus-серверов в единое представление.
*   **Высокая доступность:** Репликация и отказоустойчивость.
*   **Дедупликация:** Удаление дубликатов метрик при использовании нескольких Prometheus-серверов.

---

## 9. Ссылки для дальнейшего изучения

*   [Официальная документация Prometheus](https://prometheus.io/docs/)
*   [PromQL Cheat Sheet](https://promlabs.com/promql-cheat-sheet/)
*   [Prometheus: Up & Running](https://www.oreilly.com/library/view/prometheus-up-running/9781492034130/)
*   [Thanos Project](https://thanos.io/)
*   [Cortex Project](https://cortexmetrics.io/)
*   [VictoriaMetrics](https://victoriametrics.com/)
*   [Micrometer Deep Dive (наше руководство)](/home/ubuntu/MICROMETER_DEEP_DIVE.md)
